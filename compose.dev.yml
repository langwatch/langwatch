# Development compose with profiles
#
# Setup:
#   cp langwatch/.env.example langwatch/.env        # Add your keys
#   cp langwatch_nlp/.env.example langwatch_nlp/.env  # Add OPENAI_API_KEY for NLP
#
# Usage:
#   docker compose -f compose.dev.yml up                     # minimal: postgres + redis + app
#   docker compose -f compose.dev.yml --profile search up    # + opensearch
#   docker compose -f compose.dev.yml --profile nlp up       # + NLP + langevals
#   docker compose -f compose.dev.yml --profile scenarios up # + scenario worker + bullboard + NLP (no opensearch)
#   docker compose -f compose.dev.yml --profile test up      # + AI test server
#   docker compose -f compose.dev.yml --profile full up      # everything
#
# Per-worktree ports (create .env.dev in your worktree):
#   APP_PORT=5560
#   BULLBOARD_PORT=3000
#   AI_SERVER_PORT=3456
#
# Debug logging (set in shell or .env.dev):
#   PINO_LOG_LEVEL=debug    # For verbose worker/app logs
#
# Resource limits:
#   minimal (dev):     ~8.3GB (postgres 256 + redis 64 + app 8192)
#   scenarios:         ~9.3GB (+ workers 1536 + nlp 1024 + bullboard 128 + ai-server 128)
#   full:              ~10.0GB (+ opensearch 512 + langevals 256)
#
# Stop everything:
#   docker compose -f compose.dev.yml --profile full down

services:
  # =============================================================================
  # INFRASTRUCTURE (always started)
  # =============================================================================

  postgres:
    image: postgres:16
    restart: unless-stopped
    environment:
      POSTGRES_DB: mydb
      POSTGRES_USER: prisma
      POSTGRES_PASSWORD: prisma
    # No host port - accessed via docker network as "postgres:5432"
    volumes:
      - db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U prisma -d mydb"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 256m
          cpus: "0.5"

  redis:
    image: redis:alpine
    # No host port - accessed via docker network as "redis:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 64m
          cpus: "0.25"

  opensearch:
    image: langwatch/opensearch-lite:latest
    profiles: [search, full] # Not needed for scenarios-only work
    environment:
      - discovery.type=single-node
      - DISABLE_SECURITY_PLUGIN=true
      - "OPENSEARCH_JAVA_OPTS=-Xms256m -Xmx256m"
      - "cluster.routing.allocation.disk.threshold_enabled=false"
      - "bootstrap.memory_lock=false"
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=dev-password-not-for-prod
      - "node.store.allow_mmap=false"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    # No host port - accessed via docker network as "opensearch:9200"
    volumes:
      - opensearch-data:/usr/share/opensearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200 || exit 1"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: "1.0"

  # =============================================================================
  # INIT (installs dependencies once for Linux, all containers share)
  # =============================================================================

  init:
    image: node:24
    working_dir: /app
    volumes:
      - ./langwatch:/app
      - app_modules:/app/node_modules
      - pnpm_store:/root/.local/share/pnpm/store
    command: >
      sh -c "
        corepack enable &&
        pnpm config set store-dir /root/.local/share/pnpm/store &&
        pnpm install &&
        pnpm prisma generate
      "
    environment:
      COREPACK_ENABLE_DOWNLOAD_PROMPT: "0"

  # =============================================================================
  # APP (mounted for hot reload)
  # =============================================================================

  app:
    image: node:24
    restart: unless-stopped
    working_dir: /app
    volumes:
      - ./langwatch:/app
      - app_modules:/app/node_modules
    command: sh -c "corepack enable && pnpm run start:prepare:db && pnpm run start:app"
    ports:
      - "${APP_PORT:-5560}:5560"
    environment:
      SKIP_TIKTOKEN: 'true'
      COREPACK_ENABLE_DOWNLOAD_PROMPT: "0"
      NODE_ENV: development
      DATABASE_URL: postgresql://prisma:prisma@postgres:5432/mydb?schema=mydb
      # ELASTICSEARCH_NODE_URL comes from .env
      REDIS_URL: redis://redis:6379
      LANGWATCH_NLP_SERVICE: http://langwatch_nlp:5561
      LANGEVALS_ENDPOINT: http://langevals:5562
      # Override .env so Auth0 callback matches the dynamic host port
      BASE_HOST: http://localhost:${APP_PORT:-5560}
      NEXTAUTH_URL: http://localhost:${APP_PORT:-5560}
      # Enable scenarios UI in dev
      RELEASE_UI_SIMULATIONS_MENU_ENABLED: "1"
      RELEASE_UI_SUITES_ENABLED: "1"
    env_file:
      - langwatch/.env
    depends_on:
      init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    tty: true
    stdin_open: true
    deploy:
      resources:
        limits:
          memory: 8g
          cpus: "2.0"

  # =============================================================================
  # WORKERS (profile: workers)
  # =============================================================================

  workers:
    image: node:24
    working_dir: /app
    profiles: [workers, scenarios, full]
    volumes:
      - ./langwatch:/app
      - app_modules:/app/node_modules
    command: sh -c "corepack enable && while true; do pnpm tsx --tsconfig tsconfig.workers.json src/workers.ts; sleep 1; done"
    environment:
      SKIP_TIKTOKEN: 'true'
      COREPACK_ENABLE_DOWNLOAD_PROMPT: "0"
      NODE_ENV: development
      DATABASE_URL: postgresql://prisma:prisma@postgres:5432/mydb?schema=mydb
      # ELASTICSEARCH_NODE_URL comes from .env
      REDIS_URL: redis://redis:6379
      LANGWATCH_NLP_SERVICE: http://langwatch_nlp:5561
      LANGEVALS_ENDPOINT: http://langevals:5562
      # Override BASE_HOST for Docker networking - scenario child processes post events here
      BASE_HOST: http://app:5560
      PINO_LOG_LEVEL: ${PINO_LOG_LEVEL:-info}
      # To enable verbose scenario SDK logging, add: SCENARIO_VERBOSE: "true"
    env_file:
      - langwatch/.env
    depends_on:
      init:
        condition: service_completed_successfully
    deploy:
      resources:
        limits:
          memory: 1536m
          cpus: "0.5"

  # =============================================================================
  # NLP SERVICE (profile: nlp)
  # =============================================================================

  langwatch_nlp:
    image: langwatch/langwatch_nlp:latest
    profiles: [nlp, scenarios, full]
    env_file:
      - langwatch_nlp/.env
    # No host port - accessed via docker network as "langwatch_nlp:5561"
    environment:
      LANGWATCH_ENDPOINT: http://app:5560
    deploy:
      resources:
        limits:
          memory: 1024m
          cpus: "0.5"

  langevals:
    image: langwatch/langevals:latest
    profiles: [nlp, full]
    # No host port - accessed via docker network as "langevals:5562"
    environment:
      DISABLE_EVALUATORS_PRELOAD: "true"
    deploy:
      resources:
        limits:
          memory: 256m
          cpus: "0.5"

  # =============================================================================
  # DEBUG TOOLS (profile: debug)
  # =============================================================================

  bullboard:
    image: node:24
    working_dir: /app
    profiles: [debug, scenarios, full]
    volumes:
      - ./bullboard:/app
      - bullboard_modules:/app/node_modules
    command: sh -c "corepack enable && pnpm install && pnpm start"
    ports:
      - "${BULLBOARD_PORT:-6380}:6380"
    environment:
      COREPACK_ENABLE_DOWNLOAD_PROMPT: "0"
      REDIS_URL: redis://redis:6379
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: "0.5"

  # =============================================================================
  # TEST TOOLS (profile: test)
  # =============================================================================

  ai-server:
    image: node:24
    working_dir: /app
    profiles: [test, scenarios, full]
    volumes:
      - ./langwatch:/app
      - app_modules:/app/node_modules
    command: sh -c "corepack enable && pnpm tsx scripts/ai-server.ts"
    ports:
      - "${AI_SERVER_PORT:-3456}:3456"
    environment:
      COREPACK_ENABLE_DOWNLOAD_PROMPT: "0"
      LANGWATCH_ENDPOINT: "http://app:5560/"
      # LANGWATCH_API_KEY comes from langwatch/.env via env_file below
      PINO_CONSOLE_LEVEL: "debug"
      LOG_LEVEL: "debug"
    env_file:
      - langwatch/.env
    depends_on:
      init:
        condition: service_completed_successfully
    deploy:
      resources:
        limits:
          memory: 256m
          cpus: "0.25"

volumes:
  db-data:
    name: langwatch-db-data # Shared across all worktrees
  redis-data:
    name: langwatch-redis-data # Shared across all worktrees
  opensearch-data:
    name: langwatch-opensearch-data # Shared across all worktrees
  app_modules:
    name: langwatch-app-modules # Shared across all worktrees
  pnpm_store:
    name: langwatch-pnpm-store # Shared across all worktrees
  bullboard_modules:
    name: langwatch-bullboard-modules # Shared across all worktrees
