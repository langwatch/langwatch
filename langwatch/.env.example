# LANGWATCH ENV FILE
# ==================

# Copy this file to ".env" and add your secrets according to the instructions below
# to configure the infrastructure and unlock all LangWatch functionality



# BASIC CONFIGURATION

# Define the environment you are running in, you can change this to production for a production deployment
NODE_ENV="development"

# Define the base host for the application, this is the hostname and port of the application, NEXTAUTH_URL should be the same
BASE_HOST="http://localhost:5560"
NEXTAUTH_URL="http://localhost:5560"

# This is a comma separated list of the namespaces of the messages you want to print following npm `debug` library standard
DEBUG=langwatch:*



# AUTHENTICATION

# LangWatch uses next-auth for authentication, configured by default with basic email/password
# You can change this to auth0 by adding the appropriate environment variables
NEXTAUTH_PROVIDER="email"

# This is the key used to encrypt cookie keys, BE SURE TO CHANGE IT before deploying to production
# You can generate a new secret on the command line with `openssl rand -base64 32`
NEXTAUTH_SECRET="please_please_please_change_me_asap"

## DATASETS
# Options to use S3 or local storage for datasets

# A 32-byte string (in hex will be 64 characters)
#CREDENTIALS_SECRET="please_please_please_change_me_asap"

# If you want to use local storage for datasets, set this to true
#DATASET_STORAGE_LOCAL=true


# If you decide to go with auth0 as a provider instead of, be sure to uncomment and add the follow variables
#  NEXTAUTH_PROVIDER="auth0"
#  AUTH0_CLIENT_ID=""
#  AUTH0_CLIENT_SECRET=""
#  AUTH0_ISSUER=""

# If you decide to go with Azure AD as a provider instead of, be sure to uncomment and add the follow variables
#  NEXTAUTH_PROVIDER="azure-ad"
#  AZURE_CLIENT_ID=""
#  AZURE_CLIENT_SECRET=""
#  AZURE_TENANT_ID=""

# Salt used to generate JWT tokens for API authentication, be sure to change it before deploying to production as well
API_TOKEN_JWT_SECRET="change me to a random string"



# SERVICES AND INFRASTRUCTURE

# LangWatch is a composition of multiple services and databases, be sure to have all of them pointing to the right addresses
# Postgres for primary data storage
DATABASE_URL="postgresql://postgres@localhost:5432/langwatch_db?schema=langwatch_db"

# ElasticSearch-compatible endpoint for observability, storing traces, spans, events, evaluation results, doing search, filtering and analytics
ELASTICSEARCH_NODE_URL="quickwit://localhost:7280/api/v1/_elastic"
ELASTICSEARCH_API_KEY=""

# Redis for queues
REDIS_URL=""

# LangWatch NLP service powers the optimization studio, topic clustering and sentiment analysis
LANGWATCH_NLP_SERVICE="http://localhost:5561"

# LangEvals powers LangWatch evaluators and guardrails: https://github.com/langwatch/langevals/
LANGEVALS_ENDPOINT="http://localhost:5562"

# Disable PII redacting in traces and spans, PII redacting is optional in development but strongly recommended in production
DISABLE_PII_REDACTION=true
# Google DLP PII Detection is used as a fallback mechanism for PII redacting in case langevals presidio fails.
GOOGLE_APPLICATION_CREDENTIALS=

# Sendgrid is using for sending emails for triggers and new users invites
SENDGRID_API_KEY=

# Sentry, for error tracking and monitoring
SENTRY_DSN=



# MODELS

# Below are the optional env vars for different LLM models that are used for multiple LangWatch functionality, like evaluations,
# guardrails, playground, topic clustering and so on. At least Azure or OpenAI are recommended, to be able to generate embeddings.

# OpenAI, for embeddings and GPT-class LLMs
OPENAI_API_KEY=

# Azure, for embeddings and GPT-class LLMs
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_KEY=

# Google VertexAI for Gemini-class LLMs, be sure to have credentials as a stringified JSON, location can be set to e.g. "europe-west3"
GOOGLE_APPLICATION_CREDENTIALS=
VERTEXAI_PROJECT=
VERTEXAI_LOCATION=

# Anthropic, for Claude-class LLMs
ANTHROPIC_API_KEY=

# Groq, for Llama 3, Mixtral and other open-source LLMs with top inference speed
GROQ_API_KEY=
