# LANGWATCH ENV FILE
# ==================

# Copy this file to ".env" and add your secrets according to the instructions below
# to configure the infrastructure and unlock all LangWatch functionality



# BASIC CONFIGURATION

# Define the environment you are running in, you can change this to production for a production deployment
NODE_ENV="development"

# Define the base host for the application, this is the hostname and port of the application, NEXTAUTH_URL should be the same
BASE_HOST="http://localhost:3000"
NEXTAUTH_URL="http://localhost:3000"

# This is a comma separated list of the namespaces of the messages you want to print following npm `debug` library standard
DEBUG=langwatch:*



# AUTHENTICATION

# LangWatch uses next-auth for authentication, configured by default with basic email/password
# You can change this to auth0 by adding the appropriate environment variables
NEXTAUTH_PROVIDER="email"

# This is the key used to encrypt cookie keys, BE SURE TO CHANGE IT before deploying to production
# You can generate a new secret on the command line with `openssl rand -base64 32`
NEXTAUTH_SECRET="please_please_please_change_me_asap"

# If you decide to go with auth0 as a provider instead of, be sure to uncomment and add the follow variables
#  AUTH0_CLIENT_ID=""
#  AUTH0_CLIENT_SECRET=""
#  AUTH0_ISSUER=""

# Salt used to generate JWT tokens for API authentication, be sure to change it before deploying to production as well
API_TOKEN_JWT_SECRET="change me to a random string"



# SERVICES AND INFRASTRUCTURE

# LangWatch is a composition of multiple services and databases, be sure to have all of them pointing to the right addresses
# Postgres for primary data storage
DATABASE_URL="postgresql://prisma:prisma@localhost:5432/mydb?schema=mydb"

# ElasticSearch for observability, storing traces, spans, events, evaluation results, doing search, filtering and analytics
ELASTICSEARCH_NODE_URL="http://localhost:9200"
ELASTICSEARCH_API_KEY="some-random-password-which-is-greater-than-16-chars-long"
IS_OPENSEARCH="true"

# Redis for queues
REDIS_URL="redis://localhost:6379"

# LangWatch NLP service powers the optimization studio, topic clustering and sentiment analysis
LANGWATCH_NLP_SERVICE="http://localhost:8080"

# LangEvals powers LangWatch evaluators and guardrails: https://github.com/langwatch/langevals/
LANGEVALS_ENDPOINT="http://localhost:8000"

# Google DLP PII Detection is used for automatically redacting PII in traces and spans. This is optional in development
# but mandatory in production. This variable should hold the stringified credentials json.
GOOGLE_APPLICATION_CREDENTIALS=

# Sendgrid is using for sending emails for triggers and new users invites
SENDGRID_API_KEY=



# MODELS

# Below are the optional env vars for different LLM models that are used for multiple LangWatch functionality, like evaluations,
# guardrails, playground, topic clustering and so on. At least Azure or OpenAI are recommended, to be able to generate embeddings.

# OpenAI, for embeddings and GPT-class LLMs
OPENAI_API_KEY=

# Azure, for embeddings and GPT-class LLMs
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_KEY=

# Google VertexAI for Gemini-class LLMs, be sure to have credentials as a stringified JSON, location can be set to e.g. "europe-west3"
GOOGLE_APPLICATION_CREDENTIALS=
VERTEXAI_PROJECT=
VERTEXAI_LOCATION=

# Anthropic, for Claude-class LLMs
ANTHROPIC_API_KEY=

# Groq, for Llama 3, Mixtral and other open-source LLMs with top inference speed
GROQ_API_KEY=
